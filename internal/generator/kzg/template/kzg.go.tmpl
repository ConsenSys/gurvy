import (
	"errors"
	"math/big"
	"math/bits"

	"github.com/consensys/gnark-crypto/ecc/{{ .Name }}"
	"github.com/consensys/gnark-crypto/ecc/{{ .Name }}/fr"
	"github.com/consensys/gnark-crypto/ecc/{{ .Name }}/fr/fft"
	"github.com/consensys/gnark-crypto/ecc/{{ .Name }}/fr/polynomial"
	"github.com/consensys/gnark-crypto/fiat-shamir"
	"github.com/consensys/gnark-crypto/internal/parallel"
)

var (
	ErrInvalidNbDigests              = errors.New("number of digests is not the same as the number of polynomials")
	ErrInvalidPolynomialSize         = errors.New("the size of the polynomials exceeds the size of the domain")
	ErrVerifyOpeningProof            = errors.New("can't verify opening proof")
	ErrVerifyBatchOpeningSinglePoint = errors.New("can't verify batch opening proof at single point")
)

// Digest commitment of a polynomial.
type Digest = {{ .CurvePackage }}.G1Affine

// Scheme stores KZG data
type Scheme struct {
	// Domain to perform polynomial division. The size of the domain is the lowest power of 2 greater than Size.
	Domain *fft.Domain

	// SRS stores the result of the MPC
	SRS *SRS
}

// SRS stores the result of the MPC
// len(SRS.G1) can be larger than domain size
type SRS struct {
	G1 []{{ .CurvePackage }}.G1Affine  // [gen [alpha]gen , [alpha**2]gen, ... ]
	G2 [2]{{ .CurvePackage }}.G2Affine // [gen, [alpha]gen ]
}

// NewSRS returns a new SRS using alpha as randomness source
//
// In production, a SRS generated through MPC should be used.
//
// implements io.ReaderFrom and io.WriterTo
func NewSRS(size int, bAlpha *big.Int) *SRS {
	var srs SRS
	srs.G1 = make([]{{ .CurvePackage }}.G1Affine, size)

	var alpha fr.Element
	alpha.SetBigInt(bAlpha)

	_, _, gen1Aff, gen2Aff := {{ .CurvePackage }}.Generators()
	srs.G1[0] = gen1Aff
	srs.G2[0] = gen2Aff
	srs.G2[1].ScalarMultiplication(&gen2Aff, bAlpha)

	alphas := make([]fr.Element, size-1)
	alphas[0] = alpha
	for i := 1; i < len(alphas); i++ {
		alphas[i].Mul(&alphas[i-1], &alpha)
	}
	for i := 0; i < len(alphas); i++ {
		alphas[i].FromMont()
	}
	g1s := {{ .CurvePackage }}.BatchScalarMultiplicationG1(&gen1Aff, alphas)
	copy(srs.G1[1:], g1s)

	return &srs
}

// OpeningProof KZG proof for opening at a single point.
//
// implements io.ReaderFrom and io.WriterTo
type OpeningProof struct {
	// H quotient polynomial (f - f(z))/(x-z)
	H {{ .CurvePackage }}.G1Affine

	// Point at which the polynomial is evaluated
	Point fr.Element

	// ClaimedValue purported value
	ClaimedValue fr.Element
}

// BatchOpeningProof opening proof for many polynomials at the same point
//
// implements io.ReaderFrom and io.WriterTo
type BatchOpeningProof struct {
	// H quotient polynomial Sum_i gamma**i*(f - f(z))/(x-z)
	H {{ .CurvePackage }}.G1Affine

	// Point at which the polynomials are evaluated
	Point fr.Element

	// ClaimedValues purported values
	ClaimedValues []fr.Element
}

// Commit commits to a polynomial using a multi exponentiation with the SRS.
// It is assumed that the polynomial is in canonical form, in Montgomery form.
//
// * p polynomial to commit
func (s *Scheme) Commit(p polynomial.Polynomial) (Digest, error) {

	if p.Degree() >= s.Domain.Cardinality {
		return Digest{}, ErrInvalidPolynomialSize
	}

	var res {{ .CurvePackage }}.G1Affine

	// ensure we don't modify p
	pCopy := make(polynomial.Polynomial, s.Domain.Cardinality)
	copy(pCopy, p)

	parallel.Execute(len(p), func(start, end int) {
		for i := start; i < end; i++ {
			pCopy[i].FromMont()
		}
	})
	res.MultiExp(s.SRS.G1, pCopy)

	return res, nil
}

// Open computes an opening proof of polynomial p at given point.
//
// * point points at which the polynomial is evaluated
// * p polynomial to open
func (s *Scheme) Open(point *fr.Element, p polynomial.Polynomial) (OpeningProof, error) {

	if p.Degree() >= s.Domain.Cardinality {
		return OpeningProof{}, ErrInvalidPolynomialSize
	}

	// build the proof
	res := OpeningProof{
		Point:        *point,
		ClaimedValue: p.Eval(point),
	}

	// compute H
	h := dividePolyByXminusA(s.Domain, p, res.ClaimedValue, res.Point)

	// commit to H
	hCommit, err := s.Commit(h)
	if err != nil {
		return OpeningProof{}, err
	}
	res.H.Set(&hCommit)

	return res, nil
}

// Verify verifies a KZG opening proof at a single point
//
// * digest committed polynomial
// * proof openign proof of digest
func (s *Scheme) Verify(digest *Digest, proof *OpeningProof) error {

	// comm(f(a))
	var claimedValueG1Aff {{ .CurvePackage }}.G1Affine
	var claimedValueBigInt big.Int
	proof.ClaimedValue.ToBigIntRegular(&claimedValueBigInt)
	claimedValueG1Aff.ScalarMultiplication(&s.SRS.G1[0], &claimedValueBigInt)

	// [f(alpha) - f(a)]G1Jac
	var fminusfaG1Jac, tmpG1Jac {{ .CurvePackage }}.G1Jac
	fminusfaG1Jac.FromAffine(digest)
	tmpG1Jac.FromAffine(&claimedValueG1Aff)
	fminusfaG1Jac.SubAssign(&tmpG1Jac)

	// [-H(alpha)]G1Aff
	var negH {{ .CurvePackage }}.G1Affine
	negH.Neg(&proof.H)

	// [alpha-a]G2Jac
	var alphaMinusaG2Jac, genG2Jac, alphaG2Jac {{ .CurvePackage }}.G2Jac
	var pointBigInt big.Int
	proof.Point.ToBigIntRegular(&pointBigInt)
	genG2Jac.FromAffine(&s.SRS.G2[0])
	alphaG2Jac.FromAffine(&s.SRS.G2[1])
	alphaMinusaG2Jac.ScalarMultiplication(&genG2Jac, &pointBigInt).
		Neg(&alphaMinusaG2Jac).
		AddAssign(&alphaG2Jac)

	// [alpha-a]G2Aff
	var xminusaG2Aff {{ .CurvePackage }}.G2Affine
	xminusaG2Aff.FromJacobian(&alphaMinusaG2Jac)

	// [f(alpha) - f(a)]G1Aff
	var fminusfaG1Aff {{ .CurvePackage }}.G1Affine
	fminusfaG1Aff.FromJacobian(&fminusfaG1Jac)

	// e([-H(alpha)]G1Aff, G2gen).e([-H(alpha)]G1Aff, [alpha-a]G2Aff) ==? 1
	check, err := {{ .CurvePackage }}.PairingCheck(
		[]{{ .CurvePackage }}.G1Affine{fminusfaG1Aff, negH},
		[]{{ .CurvePackage }}.G2Affine{s.SRS.G2[0], xminusaG2Aff},
	)
	if err != nil {
		return err
	}
	if !check {
		return ErrVerifyOpeningProof
	}
	return nil
}

// BatchOpenSinglePoint creates a batch opening proof at _val of a list of polynomials.
// It's an interactive protocol, made non interactive using Fiat Shamir.
// point is the point at which the polynomials are opened.
// digests is the list of committed polynomials to open, need to derive the challenge using Fiat Shamir.
// polynomials is the list of polynomials to open.
//
// * point point on which the polynomials are evaluated
// * digests list of committed polynomials opened by the proof
// * polynomials list of polynomials to open
func (s *Scheme) BatchOpenSinglePoint(point *fr.Element, digests []Digest, polynomials []polynomial.Polynomial) (BatchOpeningProof, error) {

	nbDigests := len(digests)
	if nbDigests != len(polynomials) {
		return BatchOpeningProof{}, ErrInvalidNbDigests
	}

	var res BatchOpeningProof

	// compute the purported values
	res.ClaimedValues = make([]fr.Element, len(polynomials))
	for i := 0; i < len(polynomials); i++ {
		res.ClaimedValues[i] = polynomials[i].Eval(point)
	}

	// set the point at which the evaluation is done
	res.Point.Set(point)

	// derive the challenge gamma, binded to the point and the commitments
	gamma, err := deriveGamma(res.Point, digests)
	if err != nil {
		return BatchOpeningProof{}, err
	}

	// fold Digests and Claimed values
	var foldedEvaluations fr.Element
	foldedEvaluations.Set(&res.ClaimedValues[nbDigests-1])
	foldedDigests := polynomials[nbDigests-1].Clone()
	for i := nbDigests - 2; i >= 0; i-- {
		foldedEvaluations.Mul(&foldedEvaluations, &gamma).
			Add(&foldedEvaluations, &res.ClaimedValues[i])
		foldedDigests.ScaleInPlace(&gamma)
		foldedDigests.Add(polynomials[i], foldedDigests)
	}

	// compute H
	h := dividePolyByXminusA(s.Domain, foldedDigests, foldedEvaluations, res.Point)
	c, err := s.Commit(h)
	if err != nil {
		return BatchOpeningProof{}, err
	}

	res.H.Set(&c)

	return res, nil
}

// FoldProof fold the digests and the proofs in batchOpeningProof using Fiat Shamir
// to obtain an opening proof at a single point.
//
// * digests list of digests on which batchOpeningProof is based
// * batchOpeningProof opening proof of digests
// * returns an opening proof, the folded version of batchOpeningProof, at Digest, the folded version of digests
func (s *Scheme) FoldProof(digests []Digest, batchOpeningProof *BatchOpeningProof) (OpeningProof, Digest, error) {

	nbDigests := len(digests)

	// check consistancy between numbers of claims vs number of digests
	if nbDigests != len(batchOpeningProof.ClaimedValues) {
		return OpeningProof{}, Digest{}, ErrInvalidNbDigests
	}

	// derive the challenge gamma, binded to the point and the commitments
	gamma, err := deriveGamma(batchOpeningProof.Point, digests)
	if err != nil {
		return OpeningProof{}, Digest{}, ErrInvalidNbDigests
	}

	// fold the claimed values and digests
	foldedDigests, foldedEvaluations := fold(digests, batchOpeningProof.ClaimedValues, gamma)

	// create the folded opening proof
	var res OpeningProof
	res.ClaimedValue.Set(&foldedEvaluations)
	res.H.Set(&batchOpeningProof.H)
	res.Point.Set(&batchOpeningProof.Point)

	return res, foldedDigests, nil
}

// BatchVerifySinglePoint verifies a batched opening proof at a single point of a list of polynomials.
//
// * digests list of digests on which opening proof is done
// * batchOpeningProof proof of correct opening on the digests
func (s *Scheme) BatchVerifySinglePoint(digests []Digest, batchOpeningProof *BatchOpeningProof) error {

	// fold the proof
	foldedProof, foldedDigest, err := s.FoldProof(digests, batchOpeningProof)
	if err != nil {
		return err
	}

	// verify the foldedProof againts the foldedDigest
	err = s.Verify(&foldedDigest, &foldedProof)
	return err

}

// fold folds digests and evaluations using Fiat Shamir
//
// * digests list of digests to fold
// * evaluations list of evaluations to fold
// * gamma value used to fold digests and evaluations
func fold(digests []Digest, evaluations []fr.Element, gamma fr.Element) (Digest, fr.Element) {

	// length inconsistancy between digests and evaluations should have been done before calling this function
	nbDigests := len(digests)

	// fold the claimed values
	var foldedEvaluations fr.Element
	foldedEvaluations.Set(&evaluations[nbDigests-1])
	for i := nbDigests - 2; i >= 0; i-- {
		foldedEvaluations.Mul(&foldedEvaluations, &gamma).
			Add(&foldedEvaluations, &evaluations[i])
	}

	// fold the digests
	var acc fr.Element
	acc.SetOne()
	gammai := make([]fr.Element, len(digests))
	gammai[0].SetOne().FromMont()
	for i := 1; i < len(digests); i++ {
		acc.Mul(&acc, &gamma)
		gammai[i].Set(&acc).FromMont()
	}
	var foldedDigests Digest
	_digests := make([]{{ .CurvePackage }}.G1Affine, len(digests))
	for i := 0; i < len(digests); i++ {
		_digests[i].Set(&digests[i]) // copy to ensure the digests are not modified
	}

	foldedDigests.MultiExp(_digests, gammai)

	// folding done
	return foldedDigests, foldedEvaluations

}

// deriveGamma derives a challenge using Fiat Shamir to fold proofs.
func deriveGamma(point fr.Element, digests []Digest) (fr.Element, error) {

	// derive the challenge gamma, binded to the point and the commitments
	fs := fiatshamir.NewTranscript(fiatshamir.SHA256, "gamma")
	if err := fs.Bind("gamma", point.Marshal()); err != nil {
		return fr.Element{}, err
	}
	for i := 0; i < len(digests); i++ {
		if err := fs.Bind("gamma", digests[i].Marshal()); err != nil {
			return fr.Element{}, err
		}
	}
	gammaByte, err := fs.ComputeChallenge("gamma")
	if err != nil {
		return fr.Element{}, err
	}
	var gamma fr.Element
	gamma.SetBytes(gammaByte)

	return gamma, nil
}

// dividePolyByXminusA computes (f-f(a))/(x-a), in canonical basis, in regular form
func dividePolyByXminusA(d *fft.Domain, f polynomial.Polynomial, fa, a fr.Element) polynomial.Polynomial {

	// padd f so it has size d.Cardinality
	_f := make([]fr.Element, d.Cardinality)
	copy(_f, f)

	// compute the quotient (f-f(a))/(x-a)
	d.FFT(_f, fft.DIF, 0)

	// bit reverse shift
	bShift := uint64(64 - bits.TrailingZeros64(d.Cardinality))

	accumulator := fr.One()

	s := make([]fr.Element, len(_f))
	for i := 0; i < len(s); i++ {
		irev := bits.Reverse64(uint64(i)) >> bShift
		s[irev].Sub(&accumulator, &a)
		accumulator.Mul(&accumulator, &d.Generator)
	}
	s = fr.BatchInvert(s)

	for i := 0; i < len(_f); i++ {
		_f[i].Sub(&_f[i], &fa)
		_f[i].Mul(&_f[i], &s[i])
	}

	d.FFTInverse(_f, fft.DIT, 0)

	// the result is of degree deg(f)-1
	return _f[:len(f)-1]
}
